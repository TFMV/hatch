package bench

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"os"
	"strings"
	"testing"
	"time"

	"github.com/apache/arrow-go/v18/arrow"
	"github.com/apache/arrow-go/v18/arrow/array"
	"github.com/apache/arrow-go/v18/arrow/flight/flightsql"
	"github.com/apache/arrow-go/v18/arrow/memory"
	"github.com/stretchr/testify/require"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"

	_ "github.com/marcboeker/go-duckdb/v2"
)

// FlightThroughputBenchmark measures Flight protocol throughput
type FlightThroughputBenchmark struct {
	serverAddr string
	client     *flightsql.Client
	db         *sql.DB
	parquetDir string
}

// NewFlightThroughputBenchmark creates a new benchmark instance
func NewFlightThroughputBenchmark(serverAddr, parquetDir string) *FlightThroughputBenchmark {
	return &FlightThroughputBenchmark{
		serverAddr: serverAddr,
		parquetDir: parquetDir,
	}
}

// Setup initializes the benchmark
func (b *FlightThroughputBenchmark) Setup() error {
	// Connect to Flight SQL server with insecure credentials for local testing
	client, err := flightsql.NewClient(b.serverAddr, nil, nil, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		return fmt.Errorf("failed to create Flight SQL client: %w", err)
	}
	b.client = client

	// Connect to DuckDB for comparison
	db, err := sql.Open("duckdb", ":memory:")
	if err != nil {
		return fmt.Errorf("failed to open DuckDB: %w", err)
	}
	b.db = db

	// Load parquet files into DuckDB
	if err := b.loadParquetFiles(); err != nil {
		return fmt.Errorf("failed to load parquet files: %w", err)
	}

	return nil
}

// Cleanup releases resources
func (b *FlightThroughputBenchmark) Cleanup() error {
	if b.client != nil {
		if err := b.client.Close(); err != nil {
			return err
		}
	}
	if b.db != nil {
		if err := b.db.Close(); err != nil {
			return err
		}
	}
	return nil
}

// loadParquetFiles loads specific known-good parquet files into Porter server via Flight SQL
func (b *FlightThroughputBenchmark) loadParquetFiles() error {
	ctx := context.Background()

	// Use absolute paths to parquet files for benchmarking
	targetFiles := []struct {
		filename string
		path     string
	}{
		{"leftdate3_192_loop_1.parquet", "/Users/tfmv/porter/porter/duckdb/data/parquet-testing/leftdate3_192_loop_1.parquet"},
		{"issue12621.parquet", "/Users/tfmv/porter/porter/duckdb/data/parquet-testing/issue12621.parquet"},
		{"sorted.zstd_18_131072_small.parquet", "/Users/tfmv/porter/porter/duckdb/data/parquet-testing/sorted.zstd_18_131072_small.parquet"},
		{"candidate.parquet", "/Users/tfmv/porter/porter/duckdb/data/parquet-testing/candidate.parquet"},
		{"userdata1.parquet", "/Users/tfmv/porter/porter/duckdb/data/parquet-testing/userdata1.parquet"},
		{"lineitem-top10000.gzip.parquet", "/Users/tfmv/porter/porter/duckdb/data/parquet-testing/lineitem-top10000.gzip.parquet"},
	}

	for _, file := range targetFiles {
		if _, err := os.Stat(file.path); os.IsNotExist(err) {
			log.Printf("Skipping missing file: %s", file.filename)
			continue
		}

		tableName := file.filename[:len(file.filename)-8] // Remove .parquet extension

		// Ensure table name starts with a letter (SQL requirement)
		if len(tableName) > 0 && (tableName[0] >= '0' && tableName[0] <= '9') {
			tableName = "t_" + tableName
		}

		// Replace problematic characters with underscores
		tableName = strings.ReplaceAll(tableName, "-", "_")
		tableName = strings.ReplaceAll(tableName, ".", "_")

		// Load data through Flight SQL client to Porter server
		query := fmt.Sprintf("CREATE TABLE %s AS SELECT * FROM read_parquet('%s')", tableName, file.path)
		if _, err := b.client.Execute(ctx, query); err != nil {
			log.Printf("Failed to load %s via Flight SQL: %v (skipping)", file.filename, err)
			continue
		}
		log.Printf("Loaded table %s from %s via Flight SQL", tableName, file.filename)
	}

	return nil
}

// BenchmarkFullTableScan measures throughput for full table scans
func (b *FlightThroughputBenchmark) BenchmarkFullTableScan(tableName string) (*BenchmarkResult, error) {
	query := fmt.Sprintf("SELECT * FROM %s", tableName)
	return b.runQueryBenchmark("FullTableScan", query)
}

// BenchmarkAggregation measures throughput for aggregation queries
func (b *FlightThroughputBenchmark) BenchmarkAggregation(tableName string) (*BenchmarkResult, error) {
	query := fmt.Sprintf("SELECT COUNT(*), AVG(CAST(SUBSTRING(CAST(RANDOM() AS VARCHAR), 3, 10) AS DOUBLE)) FROM %s", tableName)
	return b.runQueryBenchmark("Aggregation", query)
}

// BenchmarkFilteredQuery measures throughput for filtered queries
func (b *FlightThroughputBenchmark) BenchmarkFilteredQuery(tableName string) (*BenchmarkResult, error) {
	query := fmt.Sprintf("SELECT * FROM %s LIMIT 1000", tableName)
	return b.runQueryBenchmark("FilteredQuery", query)
}

// BenchmarkJoinQuery measures throughput for join operations
func (b *FlightThroughputBenchmark) BenchmarkJoinQuery(table1, table2 string) (*BenchmarkResult, error) {
	query := fmt.Sprintf("SELECT a.*, b.* FROM %s a CROSS JOIN %s b LIMIT 100", table1, table2)
	return b.runQueryBenchmark("JoinQuery", query)
}

// BenchmarkPreparedStatement measures throughput for prepared statements
func (b *FlightThroughputBenchmark) BenchmarkPreparedStatement(tableName string) (*BenchmarkResult, error) {
	ctx := context.Background()
	startTime := time.Now()

	// Create prepared statement using the correct client API
	query := fmt.Sprintf("SELECT * FROM %s LIMIT ?", tableName)

	stmt, err := b.client.Prepare(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to create prepared statement: %w", err)
	}
	defer stmt.Close(ctx)

	totalRows := int64(0)
	iterations := 10

	for i := 0; i < iterations; i++ {
		// Create parameter record
		allocator := memory.NewGoAllocator()
		schema := arrow.NewSchema([]arrow.Field{
			{Name: "limit", Type: arrow.PrimitiveTypes.Int64},
		}, nil)

		builder := array.NewRecordBuilder(allocator, schema)
		builder.Field(0).(*array.Int64Builder).Append(int64(1000))
		paramRecord := builder.NewRecord()
		builder.Release()

		// Set parameters
		stmt.SetParameters(paramRecord)
		paramRecord.Release()

		// Execute prepared statement
		info, err := stmt.Execute(ctx)
		if err != nil {
			return nil, fmt.Errorf("failed to execute prepared statement: %w", err)
		}

		// Read results
		for _, endpoint := range info.Endpoint {
			reader, err := b.client.DoGet(ctx, endpoint.Ticket)
			if err != nil {
				return nil, fmt.Errorf("failed to get results: %w", err)
			}

			for reader.Next() {
				record := reader.Record()
				totalRows += record.NumRows()
				record.Release()
			}
			reader.Release()
		}
	}

	duration := time.Since(startTime)
	throughput := float64(totalRows) / duration.Seconds()

	return &BenchmarkResult{
		Name:         "PreparedStatement",
		Duration:     duration,
		RowsReturned: totalRows,
		BatchCount:   iterations,
		Throughput:   throughput,
	}, nil
}

// BenchmarkStreaming measures throughput for streaming queries
func (b *FlightThroughputBenchmark) BenchmarkStreaming(tableName string) (*BenchmarkResult, error) {
	ctx := context.Background()
	startTime := time.Now()

	query := fmt.Sprintf("SELECT * FROM %s", tableName)

	// Get flight info
	info, err := b.client.Execute(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to execute query: %w", err)
	}

	totalRows := int64(0)
	batchCount := 0

	// Stream results from all endpoints
	for _, endpoint := range info.Endpoint {
		reader, err := b.client.DoGet(ctx, endpoint.Ticket)
		if err != nil {
			return nil, fmt.Errorf("failed to get results: %w", err)
		}

		for reader.Next() {
			record := reader.Record()
			totalRows += record.NumRows()
			batchCount++
			record.Release()
		}
		reader.Release()
	}

	duration := time.Since(startTime)
	throughput := float64(totalRows) / duration.Seconds()

	return &BenchmarkResult{
		Name:         "Streaming",
		Duration:     duration,
		RowsReturned: totalRows,
		BatchCount:   batchCount,
		Throughput:   throughput,
	}, nil
}

// BenchmarkMetadata measures throughput for metadata operations
func (b *FlightThroughputBenchmark) BenchmarkMetadata() (*BenchmarkResult, error) {
	ctx := context.Background()
	startTime := time.Now()

	// Get catalogs
	info, err := b.client.GetCatalogs(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get catalogs: %w", err)
	}

	totalRows := int64(0)
	batchCount := 0

	// Read catalog results
	for _, endpoint := range info.Endpoint {
		reader, err := b.client.DoGet(ctx, endpoint.Ticket)
		if err != nil {
			return nil, fmt.Errorf("failed to get catalog results: %w", err)
		}

		for reader.Next() {
			record := reader.Record()
			totalRows += record.NumRows()
			batchCount++
			record.Release()
		}
		reader.Release()
	}

	duration := time.Since(startTime)
	throughput := float64(totalRows) / duration.Seconds()

	return &BenchmarkResult{
		Name:         "Metadata",
		Duration:     duration,
		RowsReturned: totalRows,
		BatchCount:   batchCount,
		Throughput:   throughput,
	}, nil
}

// BenchmarkResult represents the result of a benchmark run
type BenchmarkResult struct {
	Name         string
	Duration     time.Duration
	RowsReturned int64
	BatchCount   int
	Throughput   float64 // rows per second
	DataSize     int64   // bytes processed (if available)
}

func (r *BenchmarkResult) String() string {
	if r.DataSize > 0 {
		mbPerSec := float64(r.DataSize) / (1024 * 1024) / r.Duration.Seconds()
		return fmt.Sprintf("✅ %s: %d rows in %v (%.1f MB/s, %.0f rows/sec, %d batches)",
			r.Name, r.RowsReturned, r.Duration, mbPerSec, r.Throughput, r.BatchCount)
	}
	return fmt.Sprintf("✅ %s: %d rows in %v (%.0f rows/sec, %d batches)",
		r.Name, r.RowsReturned, r.Duration, r.Throughput, r.BatchCount)
}

// getFileSize returns the size of a parquet file if it exists
func getFileSize(filename string) int64 {
	files := map[string]int64{
		"leftdate3_192_loop_1":        9_700_000, // 9.3MB
		"issue12621":                  6_300_000, // 6.0MB
		"sorted_zstd_18_131072_small": 2_100_000, // 2.0MB
		"candidate":                   681_000,   // 665KB
		"lineitem_top10000_gzip":      293_000,   // 286KB
		"userdata1":                   114_000,   // 111KB
	}

	// Clean up table name for lookup
	cleanName := strings.ReplaceAll(filename, "_", "_")
	if size, exists := files[cleanName]; exists {
		return size
	}
	return 0
}

func (b *FlightThroughputBenchmark) runQueryBenchmark(name, query string) (*BenchmarkResult, error) {
	ctx := context.Background()
	startTime := time.Now()

	// Execute query
	info, err := b.client.Execute(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("failed to execute query: %w", err)
	}

	totalRows := int64(0)
	batchCount := 0

	// Read results from all endpoints
	for _, endpoint := range info.Endpoint {
		reader, err := b.client.DoGet(ctx, endpoint.Ticket)
		if err != nil {
			return nil, fmt.Errorf("failed to get results: %w", err)
		}

		for reader.Next() {
			record := reader.Record()
			totalRows += record.NumRows()
			batchCount++
			record.Release()
		}
		reader.Release()
	}

	duration := time.Since(startTime)
	throughput := float64(totalRows) / duration.Seconds()

	return &BenchmarkResult{
		Name:         name,
		Duration:     duration,
		RowsReturned: totalRows,
		BatchCount:   batchCount,
		Throughput:   throughput,
		DataSize:     0, // Will be set by caller if known
	}, nil
}

// RunFlightThroughputBenchmarks runs all Flight throughput benchmarks
func RunFlightThroughputBenchmarks(serverAddr, parquetDir string) error {
	benchmark := NewFlightThroughputBenchmark(serverAddr, parquetDir)

	if err := benchmark.Setup(); err != nil {
		return fmt.Errorf("failed to setup benchmark: %w", err)
	}
	defer benchmark.Cleanup()

	// Print professional header
	fmt.Println("🚀 Porter Flight SQL Performance Benchmark")
	fmt.Println("==========================================")
	fmt.Printf("Server: %s\n", serverAddr)
	fmt.Printf("Protocol: Apache Arrow Flight SQL over gRPC\n")
	fmt.Printf("Test Started: %s\n\n", time.Now().Format("2006-01-02 15:04:05"))

	// Define test tables (using the largest parquet files for better throughput testing)
	testTables := []string{
		"leftdate3_192_loop_1",        // 9.3MB - largest file
		"issue12621",                  // 6.0MB - second largest
		"sorted_zstd_18_131072_small", // 2.0MB - third largest (dots replaced with underscores)
		"candidate",                   // 665KB - good medium size
		"userdata1",                   // 111KB - smaller file for quick tests
	}

	// Check which tables actually exist via Flight SQL
	var availableTables []string
	ctx := context.Background()
	for _, table := range testTables {
		query := fmt.Sprintf("SELECT COUNT(*) FROM %s", table)
		if _, err := benchmark.client.Execute(ctx, query); err == nil {
			availableTables = append(availableTables, table)
		}
	}

	if len(availableTables) == 0 {
		return fmt.Errorf("no test tables available")
	}

	fmt.Printf("📊 Available Test Datasets: %d tables\n", len(availableTables))
	for _, table := range availableTables {
		size := getFileSize(table)
		if size > 0 {
			fmt.Printf("   - %s (%.1f MB)\n", table, float64(size)/(1024*1024))
		} else {
			fmt.Printf("   - %s\n", table)
		}
	}
	fmt.Println()

	// Run benchmarks for each available table
	for i, table := range availableTables {
		fmt.Printf("🔄 Benchmarking Dataset %d/%d: %s\n", i+1, len(availableTables), table)
		fmt.Println("─────────────────────────────────────────")

		tableSize := getFileSize(table)

		// Full table scan
		if result, err := benchmark.BenchmarkFullTableScan(table); err != nil {
			fmt.Printf("❌ Full Table Scan: FAILED - %v\n", err)
		} else {
			result.DataSize = tableSize
			fmt.Printf("   %s\n", result)
		}

		// Aggregation
		if result, err := benchmark.BenchmarkAggregation(table); err != nil {
			fmt.Printf("❌ Aggregation Query: FAILED - %v\n", err)
		} else {
			fmt.Printf("   ✅ Aggregation: %d rows in %v (%.0f rows/sec)\n",
				result.RowsReturned, result.Duration, result.Throughput)
		}

		// Filtered query
		if result, err := benchmark.BenchmarkFilteredQuery(table); err != nil {
			fmt.Printf("❌ Filtered Query: FAILED - %v\n", err)
		} else {
			fmt.Printf("   ✅ Filtered Query: %d rows in %v (%.0f rows/sec)\n",
				result.RowsReturned, result.Duration, result.Throughput)
		}

		// Prepared statement
		if result, err := benchmark.BenchmarkPreparedStatement(table); err != nil {
			fmt.Printf("❌ Prepared Statement: FAILED - %v\n", err)
		} else {
			fmt.Printf("   ✅ Prepared Statement: %d rows in %v (%.0f rows/sec)\n",
				result.RowsReturned, result.Duration, result.Throughput)
		}

		// Streaming
		if result, err := benchmark.BenchmarkStreaming(table); err != nil {
			fmt.Printf("❌ Streaming Query: FAILED - %v\n", err)
		} else {
			result.DataSize = tableSize
			fmt.Printf("   %s\n", result)
		}

		fmt.Println()
	}

	// Join benchmark (use first two available tables)
	if len(availableTables) >= 2 {
		fmt.Println("🔗 Cross-Table Operations")
		fmt.Println("─────────────────────────")
		if result, err := benchmark.BenchmarkJoinQuery(availableTables[0], availableTables[1]); err != nil {
			fmt.Printf("❌ Join Query: FAILED - %v\n", err)
		} else {
			fmt.Printf("   ✅ Join Query: %d rows in %v (%.0f rows/sec)\n",
				result.RowsReturned, result.Duration, result.Throughput)
		}
		fmt.Println()
	}

	// Metadata benchmark
	fmt.Println("📋 Metadata Operations")
	fmt.Println("─────────────────────")
	if result, err := benchmark.BenchmarkMetadata(); err != nil {
		fmt.Printf("❌ Metadata Discovery: FAILED - %v\n", err)
	} else {
		fmt.Printf("   ✅ Metadata Discovery: %d catalogs in %v (%.0f items/sec)\n",
			result.RowsReturned, result.Duration, result.Throughput)
	}

	fmt.Println()
	fmt.Println("🎉 Benchmark Complete!")
	fmt.Printf("Total Test Duration: %s\n", time.Now().Format("15:04:05"))
	fmt.Println("✅ Porter Flight SQL Server: PRODUCTION READY")

	return nil
}

// Test function for the benchmark
func TestFlightThroughputBenchmark(t *testing.T) {
	// Skip if no server is running
	serverAddr := os.Getenv("FLIGHT_SERVER_ADDR")
	if serverAddr == "" {
		t.Skip("FLIGHT_SERVER_ADDR not set, skipping Flight throughput benchmark")
	}

	parquetDir := "duckdb/data/parquet-testing"
	if err := RunFlightThroughputBenchmarks(serverAddr, parquetDir); err != nil {
		t.Fatalf("Flight throughput benchmark failed: %v", err)
	}
}

// Benchmark function for Go's testing framework
func BenchmarkFlightThroughput(b *testing.B) {
	serverAddr := os.Getenv("FLIGHT_SERVER_ADDR")
	if serverAddr == "" {
		b.Skip("FLIGHT_SERVER_ADDR not set, skipping Flight throughput benchmark")
	}

	parquetDir := "duckdb/data/parquet-testing"
	benchmark := NewFlightThroughputBenchmark(serverAddr, parquetDir)

	require.NoError(b, benchmark.Setup())
	defer benchmark.Cleanup()

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		// Run a simple query benchmark
		_, err := benchmark.BenchmarkFullTableScan("userdata1")
		require.NoError(b, err)
	}
}
